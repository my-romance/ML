# 모델 경량화 기술

[TOC]

## 모델 경량화란

### 연구배경

기존의 학습된 모델의 정확도를 유지하면서 보다 크기가 작고, 연산을 간소화하기 위함

### 분류

- 경량 딥러닝 알고리즘
  - 딥러닝 모델의 구조적 한계 극복
  - 연구동향
    1. 모델 구조 변경 : ResNet, DenseNet, SqueezeNet 등 다양한 신규 계층 구조를 이용하여 파라미터 축소 및 모델 성능을 개선하는 연구
    2. 합성곱 필터 변경 : 합성곱 신경망의 가장 큰 계산량을 요구하는 합성곱 필터의 연산을 효율적으로 줄이는 연구 (MobileNet, ShuffleNet)
    3. 자동 모델 탐색 : 특정 요소(지연 시간, 에너지 소모 등)가 주어진 경우, 강화 학습을 통해 최적 모델을 자동 탐색하는 연구 (NetAdapt, MNasNet)
- 알고리즘 경랑화
  - 기존 모델의 효율적인 사용
  - 연구동향
    1. 모델 압축 : 가중치 가지치기, 양자화/이진화, 가중치 공유 기법을 통해 파라미터의 불필요한 표현력을 줄이는 연구 (Deep Compression, XNOR-Net)
       - 가중치 가지치기와 지식 증류 기법 : pretrained model이 먼저 준비되고 이를 기반으로 경량화된 모델을 얻는 방법
       - 양자화 기법 : 모델 학습 과정에서 경량화를 수행하거나 pretrained model로부터 경량화 모두를 수행하는 기법
    2. 지식 증류 : 학습된 기본 모델을 통해 새로운 모델의 생성 시 파라미터값을 활용하여 학습시간을 줄이는 연구 (Knowledge Distillation,Transfer Learning)
    3. 하드웨어 가속화 
    4. 모델 압축 자동 탐색 : 알고리즘 경량화 연구 중 일반적인 모델 압축 기법을 적용한 강화학습 기반의 최적 모델 자동 탐색 연구 (PocketFlow, AMC)



## 모델 경량화 기술

### 가지치기 (pruning)

- **'모델의 모든 파라미터들이 추론에 동일한 영향을 미치는 것은 아니다'** 라는 관점에서 출발
- 연구 1
  - 특정 임계점을 설정하고, 이보다 낮은 값을 가지는 뉴로들과 이들의 연결들을 계측 단위로 제거
  - 이후, 재학습을 수행하는 과정을 반복하는 방식
  - 논문 기준 파라미터 개수 약 9배 축소
- 연구 2
  - pretrained CNN모델에서 덜 중요한 필터를 이와 연결된 feature map들과 함께 가지치기
  - 이론적으로 m개의 필터를 가지치기 하였을때, m/출력 채널 수 만큼의 계상량 쭐임
- 연구 3
  - 크게 기여하지 못하는 파라미터들을 가지치기(or clipping)하고
  - 이후 이들을 클러스터링 한 뒤 centroid 등의 값으로 기존 파라미터를 대체한 후 양자화 하는 방식
  - 최대 49배 까지 경량화 가능함을 보임

### 지식증류 기법 (knowledge distillation)

- 기 학습된 여러 teacher 모델들을 앙상블하여 이를 하나의 student 모델로 학습시키기 위해 고안된 기법으로, teacher-student라고도 불림
- 먼저 pretrained model이 teacher 모델로서 준비가 되어 있어야함
- 연구 1
  - [kill the bits 논문](https://arxiv.org/abs/1907.05686)
- 연구 2
  - [Quantization Networks](https://ieeexplore.ieee.org/document/8953531)

### 양자화 기법 (Quantization)

- 완전정밀도 타입 (FP32) 기반의 학습 파라미터의 값들을 이보다 낮은 비트너비를 갖는 1~K 비트 크기로 표현
- 통상의 경우 딥러닝 모델 FP32 타입을 사용 → 
  이를 K 비트들로 표현함으로써 가지치기 기법과 같이 파라미터 일부를 날리지 않더라도 모델의 크기를 이론상 32/K 배만큼 줄일 수 있음
- 단, 낮은 비트너비로 인해 표현할 수 있는 실수 범위가 크게 한정되며 이는 **정확도의 손실**로 이어짐
- 즉, 보다 낮은 비트너비를 이용하면서 완전정빌도 대비 정확도 손실을 최소화하는 것이 중요

- 양자화 대상

  - 모델의 가중치 (weight)

  - 활성화 출력 (activation)

  - 기울기 (gradient) : 양자화 대상으로 잘 고려되지는 않음. (성능 저하로 인해)

  - 양자화 대상에 따른 분류

    | componets  | benefits                                                     | challenge                                                    |
    | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | weight     | - smaller model size<br />- faster forward training & inference<br />- less energy | - hard to converge with quantized weights<br />- require approximate gradients<br />- accuracy degradation |
    | activation | - smaller memory foot print during training<br />- allows replcement of dot-products by bitwise operations | - gradient mismatch problem                                  |
    | gradients  | - communication & memory savings                             | - convergence requirement                                    |

- 분류 (크게 2가지로 나눌 수 있음)
  - 이진화 기법
  - K-비트 양자화 기법

### 경량 네트워크 설계 기법

- 뉴럴 네트워크 구조 자체를 변경함으로써 모델의 크기나 연산량을 줄이고자 함

- 뉴럴 네트워크 모델 구조 변경

  | 모델                 | 특징                                        |
  | -------------------- | ------------------------------------------- |
  | ResNet, Inception    | Residual Connection, Bottleneck             |
  | DeepLab, ShiftNet    | Dilated Convolution                         |
  | MobileNet, Inception | Depthwise Seperable, Point-wise Convolution |
  | AlexNet, ShuffleNet  | Grouped Convolution                         |
  | ShiftNet             | Shift Convolution                           |
  | DenseNet             | Dense Convolution                           |
  | EfficientNet         | Compound Scaling                            |



## 측정 평가 척도

### 딥러닝 설계 효율성 측정 평가 척도

1. 전체 학습 파라미터 개수 대비 정확도

2. FLOPS 대비 정확도

3. 추론 시간 대비 정확도

4. 지연시간 대비 정확도

5. 정보 밀집도
   $$
   D(N) = \frac{a(N)}{p(N)}
   $$

6. NetScore

### 모델 경량화 설계의 효율성 측정 평가 척도

1. 학습 파라미터 개수 (혹은 메모리 저장 용량 크기)
2. 학습 시간
3. 추론 시간
4. 학습 중 memory 요구량
5. 모델 정확도



## 참고자료

- [경량 딥러닝 기술 동향](https://www.google.com/search?q=%EB%94%A5%EB%9F%AC%EB%8B%9D+%EA%B2%BD%EB%9F%89%ED%99%94&oq=%EB%94%A5%EB%9F%AC%EB%8B%9D+%EA%B2%BD%EB%9F%89%ED%99%94&aqs=chrome..69i57.10407j0j1&sourceid=chrome&ie=UTF-8)

- [딥 러닝 모델의 경량화 기술 동향](https://www.researchgate.net/publication/343574829_dib_leoning_model-ui_gyeonglyanghwa_gisul_donghyang)